{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd658863",
   "metadata": {},
   "source": [
    "# Data Cleaning!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2006003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import janitor\n",
    "import pandas as pd\n",
    "import ydata_profiling as yp\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8aea69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    \"\"\"\n",
    "    One-hot encodes the categorical columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The one-hot encoded DataFrame.\n",
    "    \"\"\"\n",
    "    # Identify categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "    non_categorical_cols = df.select_dtypes(exclude=[\"object\", \"category\"]).columns\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    encoder = OneHotEncoder()\n",
    "\n",
    "    encoded_array = encoder.fit_transform(df[categorical_cols]).toarray()\n",
    "\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_array, columns=encoder.get_feature_names_out(categorical_cols)\n",
    "    )\n",
    "\n",
    "    result_df = pd.concat(\n",
    "        [df[non_categorical_cols].reset_index(drop=True), encoded_df], axis=1\n",
    "    )\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "5678258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise(df, non_categorical_cols):\n",
    "    \"\"\"\n",
    "    One-hot encodes the categorical columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to be one-hot encoded.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The one-hot encoded DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    # Standardise categorical columns\n",
    "    encoder = StandardScaler()\n",
    "\n",
    "    encoded_array = encoder.fit_transform(df[non_categorical_cols])\n",
    "\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_array, columns=encoder.get_feature_names_out(non_categorical_cols)\n",
    "    )\n",
    "\n",
    "    all_cols_set = set(df.columns)\n",
    "    non_categorical_cols_set = set(non_categorical_cols)\n",
    "    categorical_cols = all_cols_set - non_categorical_cols_set\n",
    "\n",
    "    result_df = pd.concat(\n",
    "        [\n",
    "            df[list(categorical_cols)].reset_index(drop=True),\n",
    "            encoded_df,\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    # reorder columns to have unique_id at the front\n",
    "    non_pid_cols = [col for col in result_df.columns if col != \"pid\"]\n",
    "    result_df = result_df[[\"pid\"] + non_pid_cols]\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4c389280",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df = pd.read_csv(\"data/AmesHousing.csv\")\n",
    "no_csv = pd.read_csv(\"data/na_list.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40be9ef",
   "metadata": {},
   "source": [
    "### 1.) Replace meaningful Nans with pair in na_list.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "20f702f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = dict(zip(no_csv[\"feature\"], no_csv[\"NA meaning\"]))\n",
    "\n",
    "ames_df = ames_df.fillna(value=replace_dict, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c894fa3",
   "metadata": {},
   "source": [
    "### 2.) Correct column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a3dadcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df = pd.concat(\n",
    "    [\n",
    "        ames_df.select_dtypes(None, [\"object\"]),\n",
    "        ames_df.select_dtypes([\"object\"]).apply(pd.Series.astype, dtype=\"category\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ").reindex(ames_df.columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af283e7",
   "metadata": {},
   "source": [
    "### 3.) Remove scewed, uninformative columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "10559179",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df = ames_df.clean_names(remove_special=True)\n",
    "\n",
    "column_to_remove_list = [\n",
    "    \"alley\",\n",
    "    \"land_slope\",\n",
    "    \"condition_2\",\n",
    "    \"roof_matl\",\n",
    "    \"mas_vnr_type\",\n",
    "    \"mas_vnr_type\",\n",
    "    \"mas_vnr_area\",\n",
    "    \"bsmtfin_type_2\",\n",
    "    \"heating\",\n",
    "    \"low_qual_fin_sf\",\n",
    "    \"enclosed_porch\",\n",
    "    \"3ssn_porch\",\n",
    "    \"screen_porch\",\n",
    "    \"pool_area\",\n",
    "    \"misc_feature\",\n",
    "    \"misc_val\",\n",
    "    \"mo_sold\",\n",
    "    \"yr_sold\",\n",
    "    \"sale_type\",\n",
    "    \"sale_condition\",\n",
    "    \"order\",\n",
    "]\n",
    "\n",
    "ames_df = ames_df.drop(columns=column_to_remove_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c668622",
   "metadata": {},
   "source": [
    "### 4.) bad categories get cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9ad910f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df[\"ms_zoning\"] = ames_df[\"ms_zoning\"].apply(lambda x: x.split(\" \")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3a71be",
   "metadata": {},
   "source": [
    "### 5.) one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "9aa80951",
   "metadata": {},
   "outputs": [],
   "source": [
    "ames_df = one_hot_encode(ames_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f8477",
   "metadata": {},
   "source": [
    "### 6.) standardising\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "b3615c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_categorical_cols = ames_df.select_dtypes(exclude=[\"object\", \"category\"]).columns\n",
    "non_categorical_cols = non_categorical_cols.drop([\"pid\"])\n",
    "\n",
    "ames_df = standardise(ames_df, non_categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93521e4b",
   "metadata": {},
   "source": [
    "#### BEFORE INTERPOLATION Test train split (including validation sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2073fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of test train split\n",
    "no_test_train = False\n",
    "normal_test_train = False\n",
    "test_train_with_val = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "951ce83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_test_train:\n",
    "    # drop lot_frontage due to data leakage\n",
    "    ames_df = ames_df.drop(\"lot_frontage\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a9cb9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y dataframes\n",
    "X = ames_df.drop(\"saleprice\", axis=1)\n",
    "y = ames_df[[\"pid\", \"saleprice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a7e249c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_train_with_val:\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.8, random_state=42\n",
    "    )\n",
    "\n",
    "    # split temp into 75/25 split\n",
    "    X_val1, X_temp, y_val1, y_temp = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.75, random_state=42\n",
    "    )\n",
    "\n",
    "    # next split is 2/3 (60 percent of dataset left)\n",
    "    X_val2, X_temp, y_val2, y_temp = train_test_split(\n",
    "        X_temp, y_temp, test_size=(2 / 3), random_state=42\n",
    "    )\n",
    "\n",
    "    # last split is 50/50 (40 percent of dataset left)\n",
    "    X_val3, X_val4, y_val3, y_val4 = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=42\n",
    "    )\n",
    "\n",
    "    # create dictionaries to loop through processes\n",
    "\n",
    "    X_data_dict = {\n",
    "        \"train\": X_train,\n",
    "        \"val1\": X_val1,\n",
    "        \"val2\": X_val2,\n",
    "        \"val3\": X_val3,\n",
    "        \"val4\": X_val4,\n",
    "    }\n",
    "\n",
    "    y_data_dict = {\n",
    "        \"train\": y_train,\n",
    "        \"val1\": y_val1,\n",
    "        \"val2\": y_val2,\n",
    "        \"val3\": y_val3,\n",
    "        \"val4\": y_val4,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "b8c9461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normal_test_train:\n",
    "    # 80/20 test/train split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.8, random_state=42\n",
    "    )\n",
    "    X_data_dict = {\"train\": X_train, \"test\": X_test}\n",
    "    y_data_dict = {\"train\": y_train, \"test\": y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "9f2aa702",
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_test_train:\n",
    "    X_data_dict = {\"train\": X}\n",
    "    y_data_dict = {\"train\": y}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fabd31",
   "metadata": {},
   "source": [
    "### 5.) Interpolate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ba0ee9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_steps(df):\n",
    "    try:\n",
    "        df[\"lot_frontage\"] = df[\"lot_frontage\"].fillna(df[\"lot_frontage\"].mean())\n",
    "    except KeyError as e:\n",
    "        return df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4800547",
   "metadata": {},
   "source": [
    "### 6.) One hot encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "9a144562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################train###################\n",
      "Before\n",
      "train:(586, 249)\n",
      "\n",
      "After interpolation\n",
      "train:(586, 249)\n",
      "###################val1###################\n",
      "Before\n",
      "val1:(586, 249)\n",
      "\n",
      "After interpolation\n",
      "val1:(586, 249)\n",
      "###################val2###################\n",
      "Before\n",
      "val2:(586, 249)\n",
      "\n",
      "After interpolation\n",
      "val2:(586, 249)\n",
      "###################val3###################\n",
      "Before\n",
      "val3:(586, 249)\n",
      "\n",
      "After interpolation\n",
      "val3:(586, 249)\n",
      "###################val4###################\n",
      "Before\n",
      "val4:(586, 249)\n",
      "\n",
      "After interpolation\n",
      "val4:(586, 249)\n"
     ]
    }
   ],
   "source": [
    "# find a list of non categorical columns\n",
    "# non_categorical_cols = ames_df.select_dtypes(exclude=[\"object\", \"category\"]).columns\n",
    "# non_categorical_cols = non_categorical_cols.drop([\"pid\", \"saleprice\"])\n",
    "\n",
    "# apply one hot encoding to all datasets\n",
    "for key, value in X_data_dict.items():\n",
    "    print(\n",
    "        f\"###################{key}###################\\nBefore\\n{key}:{X_data_dict[key].shape}\"\n",
    "    )\n",
    "    X_data_dict[key] = interpolation_steps(X_data_dict[key])\n",
    "    print(f\"\\nAfter interpolation\\n{key}:{X_data_dict[key].shape}\")\n",
    "    # X_data_dict[key] = one_hot_encode(X_data_dict[key])\n",
    "    # print(f\"\\nAfter 1h\\n{key}:{X_data_dict[key].shape}\")\n",
    "    # X_data_dict[key] = standardise(X_data_dict[key], non_categorical_cols)\n",
    "    # y_data_dict[key] = standardise(y_data_dict[key], [\"saleprice\"])\n",
    "    # print(f\"\\nAfter standardisation\\n{key}:{X_data_dict[key].shape}\")\n",
    "\n",
    "for key, value in X_data_dict.items():\n",
    "\n",
    "    X_data_dict[key].to_csv(f\"data/X_{key}.csv\", index=False)\n",
    "\n",
    "    y_data_dict[key].to_csv(f\"data/y_{key}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d91c49",
   "metadata": {},
   "source": [
    "# Create a massive report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "30dbefc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'profile = yp.ProfileReport(ames_df)\\nprofile.to_notebook_iframe()\\nprofile.to_file(\"eda_report.html\")'"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"profile = yp.ProfileReport(ames_df)\n",
    "profile.to_notebook_iframe()\n",
    "profile.to_file(\"eda_report.html\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
